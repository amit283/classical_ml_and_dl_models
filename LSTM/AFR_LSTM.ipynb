{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wB1E2RSsal8K",
    "outputId": "21b2cc18-e139-45c5-c943-6b134620f38c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import datetime\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import itertools\n",
    "import itertools\n",
    "import collections\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HOVDFYW5gbp6"
   },
   "outputs": [],
   "source": [
    "!pip install PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "#Authenticate and create the PyDrive client\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth=GoogleAuth()\n",
    "gauth.credentials=GoogleCredentials.get_application_default()\n",
    "drive=GoogleDrive(gauth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQFKQf43gbp8"
   },
   "outputs": [],
   "source": [
    "link =\"https://drive.google.com/open?id=18yHOyLnrSgzAabvXoev4C2yjzSThegLB\"\n",
    "fluff, id = link.split('=')\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('database.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ul9ZU7Hsal8N"
   },
   "source": [
    "## Data Read and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cSQCeybIal8O",
    "outputId": "ed54d16f-94c1-4b42-9283-3621e9089514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525814, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load the data from .sqlite file\n",
    "\n",
    "db=sqlite3.connect('database.sqlite')\n",
    "\n",
    "# select all reviews from given dataset\n",
    "# we are considering a review is positive or negative on the basis of the Score column which is nothing but a rating given\n",
    "# by a customer for a product. If a score >3 it is considered as positive elseif score<3 it is negative and score=3 is neutral\n",
    "# Therefore all reviews which are having score other than 3 are taken into account.\n",
    "\n",
    "filtered_data=pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews WHERE Score!=3\"\"\",db)\n",
    "\n",
    "# Replace this numbers in Score column as per our assumptions i.e replace 3+ with positive 1 and 3- with negative 0\n",
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "# changing reviews with score less than 3 to be positive (1) and vice-versa\n",
    "actualScore = filtered_data['Score']\n",
    "positiveNegative = actualScore.map(partition) \n",
    "filtered_data['Score'] = positiveNegative\n",
    "print(filtered_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "czTBjHMaal8Q"
   },
   "outputs": [],
   "source": [
    "# converting datestamp into string representable form as YYYY-MM-DD\n",
    "filtered_data[\"Time\"] = filtered_data[\"Time\"].map(lambda t: datetime.datetime.fromtimestamp(t).strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IsgJYvqIal8U",
    "outputId": "33f92367-c34b-4a4d-d9dc-9b7ba8707a87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364173, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is lot of duplicate data present as we can see above productId B007OSBE1U \n",
    "# have multiple duplicate reviews this is what we need to avoid.\n",
    "\n",
    "# so first step is to sort the data and then remove duplicate entries so that only\n",
    "# one copy of them should be remain in our data.\n",
    "dup_free=filtered_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"})\n",
    "# dup_free.head()\n",
    "# This is shape of our dataset of 100k datapoints after removal of dups\n",
    "dup_free.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1s8SlnKgal8X"
   },
   "outputs": [],
   "source": [
    "final_filtered_data=dup_free[dup_free.HelpfulnessNumerator<=dup_free.HelpfulnessDenominator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QUWFsL5Ual8a",
    "outputId": "338d098d-5ead-4d4d-bbbc-99b5d0790db3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364171, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3Hoy_1BMal8c",
    "outputId": "721a50f4-904a-46dd-db5d-b523821d678f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.25852107399194"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((final_filtered_data['Id'].size*1.0)/(filtered_data['Id'].size*(1.0)))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BsUEBvLVal8e"
   },
   "source": [
    "#### so after data cleanup we left with 69.25% data of 525k datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CO1nIxsCal8f"
   },
   "outputs": [],
   "source": [
    "filtered_data=filtered_data.sort_values(by='Time').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0QTZldLEal8i",
    "outputId": "5d7cacbd-8dc7-4447-8943-3b6606729025"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94647, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=filtered_data.sample(frac=0.18,random_state=2)\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "l9jN0ZRlal8k",
    "outputId": "7da87d26-507d-495f-db78-beca125ef2cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Reviews:  79928\n",
      "Positive Reviews:  14719\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive Reviews: \",final[final.Score ==1].shape[0])\n",
    "print(\"Positive Reviews: \",final[final.Score ==0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3k8FX6FJal8o"
   },
   "source": [
    "### Dataset seems balanced now with 52% positive reviews and 48% negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "YAiW3gWmnt1-",
    "outputId": "090c244c-433c-4077-f342-d5bde062bf4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xcRDcrd3al8p"
   },
   "source": [
    "## Text Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PnqvIcrCal8q"
   },
   "outputs": [],
   "source": [
    "# Now we have already done with data cleanup part. As in our dataset most cruicial or I can say most determinant feature\n",
    "# from which we can say it is positive or negative review is review Text.\n",
    "# So we are need to perform some Text Preprocessing on it before we actually convert it into word vector or vectorization\n",
    "\n",
    "# I am creating some precompiled objects for our regular expressions cause it will be used for over ~64K times (in our case)\n",
    "# as it seems fast but using regular expression is CPU expensive task so it would be faster to use precompiled search objects.\n",
    "\n",
    "_wont  = re.compile(r\"won't\")\n",
    "_cant  = re.compile(r\"can\\'t\")\n",
    "_not   = re.compile(r\"n\\'t\")\n",
    "_are   = re.compile(r\"\\'re\")\n",
    "_is    = re.compile(r\"\\'s\")\n",
    "_would = re.compile(r\"\\'d\")\n",
    "_will  = re.compile(r\"\\'ll\")\n",
    "_have  = re.compile(r\"\\'ve\")\n",
    "_am    = re.compile(r\"\\'m\")\n",
    "\n",
    "# we are ignoring \"not\" from stopwords as \"not\" plays important role for semantic analysis as it can alone change the \n",
    "# meaning of whole sentence\n",
    "stopWords = set(stopwords.words('english'))\n",
    "sw=stopWords.copy()\n",
    "sw.discard('not')\n",
    "\n",
    "def expand_abbrevated_words(phrase):\n",
    "    phrase = re.sub(_wont, \"will not\", phrase)\n",
    "    phrase = re.sub(_cant, \"can not\", phrase)\n",
    "    phrase = re.sub(_not, \" not\", phrase)\n",
    "    phrase = re.sub(_are, \" are\", phrase)\n",
    "    phrase = re.sub(_is, \" is\", phrase)\n",
    "    phrase = re.sub(_would, \" would\", phrase)\n",
    "    phrase = re.sub(_will, \" will\", phrase)\n",
    "    phrase = re.sub(_have, \" have\", phrase)\n",
    "    phrase = re.sub(_am, \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "# As this dataset is web scrapped from amazon.com while scrapping there might be a good chance that we are getting some garbage\n",
    "# characters/words/sentences in our Text data like html tags,links, alphanumeric characters so we ought to remove them\n",
    "def remove_unwanted_char(data):    \n",
    "    processed_data=[]\n",
    "    for sentence in tqdm(data):\n",
    "        sentence = re.sub(r\"http\\S+\", \"\", sentence) # this will remove links\n",
    "        sentence = BeautifulSoup(sentence, 'lxml').get_text()\n",
    "        sentence = re.sub(\"\\S*\\d\\S*\", \"\", sentence).strip() #remove alphanumeric words\n",
    "        sentence = re.sub('[^A-Za-z]+', ' ', sentence) #remove special characters\n",
    "        sentence =  expand_abbrevated_words(sentence)\n",
    "        # we need to convert everything into lower case because I dont want my model to treat same word differently\n",
    "        # if it appears in the begining of sentence and somewhere middle of sentence.\n",
    "        # Also remove stopword froms from sentences\n",
    "        sentence =\" \".join(j.lower() for j in sentence.split() if j.lower() not in sw)\n",
    "        processed_data.append(sentence)\n",
    "    return processed_data\n",
    " \n",
    "def preprocess_my_data(data):\n",
    "    return remove_unwanted_char(data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8sr4fU8Aal8s",
    "outputId": "d67164bb-8d2f-4087-e390-b183301a4ff8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94647/94647 [00:37<00:00, 2524.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_to_be_processed=final['Text'].values\n",
    "processed_data=preprocess_my_data(data_to_be_processed)\n",
    "label=final['Score']\n",
    "print(len(processed_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "o0tCGnF2al8u",
    "outputId": "9e571df8-7917-43bd-9979-3284834b442e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tried several times get good coconut flavored coffee little success boyer trick great coffee good amount coconut flavor highly recommend\n"
     ]
    }
   ],
   "source": [
    "final['CleanedText']=processed_data\n",
    "print(processed_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fFApCmSlDjZs"
   },
   "outputs": [],
   "source": [
    "reviews=processed_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y28XZ-ISD0y4"
   },
   "outputs": [],
   "source": [
    "vocab=[x.split() for x in reviews] # splitting sentences to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fBtEPdKhFIbU"
   },
   "outputs": [],
   "source": [
    "vocab=list(itertools.chain.from_iterable(vocab)) # getting vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7YyqLjUdFisd"
   },
   "outputs": [],
   "source": [
    "word_freq=collections.Counter(vocab) # word to frequency count dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SDWhfKluHDAJ",
    "outputId": "c87dc57a-01b9-4c78-a2ce-f78b317bf00f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Vocabulory :  54224\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of Vocabulory : \",len(word_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G7qYNqpEJZLx"
   },
   "outputs": [],
   "source": [
    "frequency=np.array(list(word_freq.values()))\n",
    "words=list(word_freq.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58bUAXp-O4Wa"
   },
   "outputs": [],
   "source": [
    "frequency=list(np.argsort(frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y1zro3ExO7Dp"
   },
   "outputs": [],
   "source": [
    "frequency.reverse() # to get words in descending order according to frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDxj6Ox5O9lM"
   },
   "outputs": [],
   "source": [
    "word_to_frequency_index=dict()\n",
    "# Assigning each word to its corresponding index according to it occurence frequency in descending order\n",
    "for count, index in enumerate(frequency,1):\n",
    "  word_to_frequency_index.update({words[index]:count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9we9XSQLS_mr"
   },
   "outputs": [],
   "source": [
    "top_word_freq=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNpSEpGoUAot"
   },
   "outputs": [],
   "source": [
    "# Replace each word in review with its index of occurence frequency (only top 5000 words will be replaced and others are ignored)\n",
    "def replace_word_to_occurenece_index(review):\n",
    "  updated_rev=list()\n",
    "  for word in review.split():\n",
    "    count=word_to_frequency_index[word]\n",
    "    if count<=top_word_freq:\n",
    "      updated_rev.append(count)\n",
    "  \n",
    "  return np.array(updated_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_DZK3O4TUukx"
   },
   "outputs": [],
   "source": [
    "reviews=list(map(replace_word_to_occurenece_index,reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kW6DZYc3W_IM"
   },
   "outputs": [],
   "source": [
    "reviews=np.array(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4ZDgI4OEX9zM",
    "outputId": "2e06b667-e292-4be9-802a-19090d6060e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94647"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SZ6op5apfEXg",
    "outputId": "6ec0e0aa-366e-4bd4-85e1-e071f3851039"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94647"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D-qCio3GgeXk"
   },
   "outputs": [],
   "source": [
    "max_review_length = 600\n",
    "reviews = sequence.pad_sequences(reviews, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1-hHWKfXhPXG",
    "outputId": "3fc442f9-27a1-4820-b827-884cc0b6931d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes of Train,test dataset after split: 66252 , 28395\n"
     ]
    }
   ],
   "source": [
    "x_tr, x_test, y_tr, y_test = train_test_split(reviews, label, test_size=0.3, random_state=0)\n",
    "print(\"Sizes of Train,test dataset after split: {0} , {1}\".format(len(x_tr),len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "z2rb7XExlHl0",
    "outputId": "2f43ffd4-83d7-4e3c-b841-6ac45a42237b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0902 08:07:16.445701 139849670682496 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0902 08:07:16.483319 139849670682496 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0902 08:07:16.490946 139849670682496 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0902 08:07:16.844098 139849670682496 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0902 08:07:16.867537 139849670682496 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0902 08:07:16.874839 139849670682496 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 600, 32)           160032    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,333\n",
      "Trainable params: 213,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_word_freq+1, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "oQDIEDvClard",
    "outputId": "2e520013-2a39-4edf-a6db-9f7b26218a13"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0902 08:07:17.943202 139849670682496 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "66252/66252 [==============================] - 847s 13ms/step - loss: 0.2430 - acc: 0.9065\n",
      "Epoch 2/10\n",
      "66252/66252 [==============================] - 876s 13ms/step - loss: 0.1733 - acc: 0.9341\n",
      "Epoch 3/10\n",
      "66252/66252 [==============================] - 872s 13ms/step - loss: 0.1529 - acc: 0.9418\n",
      "Epoch 4/10\n",
      "66252/66252 [==============================] - 867s 13ms/step - loss: 0.1352 - acc: 0.9494\n",
      "Epoch 5/10\n",
      "66252/66252 [==============================] - 865s 13ms/step - loss: 0.1180 - acc: 0.9564\n",
      "Epoch 6/10\n",
      "66252/66252 [==============================] - 865s 13ms/step - loss: 0.0992 - acc: 0.9642\n",
      "Epoch 7/10\n",
      "66252/66252 [==============================] - 868s 13ms/step - loss: 0.0849 - acc: 0.9707\n",
      "Epoch 8/10\n",
      "66252/66252 [==============================] - 868s 13ms/step - loss: 0.0740 - acc: 0.9756\n",
      "Epoch 9/10\n",
      "66252/66252 [==============================] - 871s 13ms/step - loss: 0.0607 - acc: 0.9802\n",
      "Epoch 10/10\n",
      "66252/66252 [==============================] - 872s 13ms/step - loss: 0.0505 - acc: 0.9839\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_tr, y_tr, nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VLDdV-zYlW6u"
   },
   "outputs": [],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mNKf5tb1DDcm",
    "outputId": "1d8a90f5-59b1-4d5d-f36a-e59d0e20f376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data :  0.9218524388201452\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on Test Data : \",scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "redzgYKTHwvm"
   },
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MmCPmWO0HzOv"
   },
   "source": [
    "We got **92.18%** accuracy on Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-cbSl6PuE9rM"
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4BjypALlFAQN"
   },
   "source": [
    "1. Traditional RNN's cannot remember the Long Term relationships between words i.e simple RNN's suffer from vanishing gradients problem as no of features or dimensions increases.\n",
    "\n",
    "2. In case of Amazon fine food reviews as words in sentences increases our model will start facing vanishing gradient problem.\n",
    "\n",
    "3. LSTM's are remedy for this problem as it has no prblem remembering the dependencies of previous inputs with the future inputs.\n",
    "\n",
    "4. LSTMS comprised of :\n",
    "   * Cell State\n",
    "   * Forget gate layer\n",
    "   * Input gate layer\n",
    "   * Output Layer\n",
    "\n",
    "5. Key thing in LSTM is Cell state.\n",
    "\n",
    "6. Forget gate layer takes care of which information need to be dropped\n",
    "\n",
    "7. Input gate takes care of which new information need to be passed and replaced with the information dropped\n",
    "\n",
    "8. output layer decides what information to be fed to next LSTM unit"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AFR_LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
